{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74803,
     "status": "ok",
     "timestamp": 1577433871806,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "oIko0oWJ7huD",
    "outputId": "f6e30604-a674-4eb1-d8b4-7834529cd2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1577433888780,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "9O_IMs8c7xhx",
    "outputId": "38f2cb67-da29-468e-e603-9d077f569f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/search_engine\n"
     ]
    }
   ],
   "source": [
    "cd drive/My Drive/search_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJAIJt0aD88w"
   },
   "source": [
    "## The Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nUr4ks0EP-G"
   },
   "source": [
    "As per the problem statement, I have to develope a stackoverflow based semantic search engine. Thus in order to understand and learn from the data, I need to gather Questions and Answers that were posted on Stack Overflow. Thus what I need are the following: \n",
    "\n",
    "- Title \n",
    "- Question body\n",
    "- Answers for that question\n",
    "- Votes for each answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKGqKYXy737I"
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqUzM6oX8CAG"
   },
   "source": [
    "I will use this https://www.kaggle.com/stackoverflow/stackoverflow dataset. I includes an archive of Stack Overflow content, including posts, votes, tags, and badges. This dataset is updated to mirror the Stack Overflow content on the Internet Archive.\n",
    "\n",
    "- I will use bq_helper which is a helper class to perform read-only BigQuery Tasks. \n",
    "Reference : https://www.kaggle.com/sohier/introduction-to-the-bq-helper-package\n",
    "- There are many tables on the Stackoverflow database, but we only need concern ourselves with **posts_questions** and **posts_answers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMqDbofZNX0A"
   },
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OdJjaxONdm8"
   },
   "outputs": [],
   "source": [
    "import bq_helper\n",
    "from bq_helper import BigQueryHelper\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk.corpus import stopwords\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWvJ9tBuRfra"
   },
   "source": [
    "## Getting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZI2FI1iD_Em"
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"credentials.json\"\n",
    "bq_assistant = BigQueryHelper(\"bigquery-public-data\", \"stackoverflow\")\n",
    "\n",
    "query = \"SELECT q.id, q.title, q.body, q.tags, a.body as answers, a.score FROM `bigquery-public-data.stackoverflow.posts_questions` AS q INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a ON q.id = a.parent_id LIMIT 1000000\"\n",
    "df = bq_assistant.query_to_pandas(query)\n",
    "df.to_csv('Original_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sJaEvot9Y_m"
   },
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('Original_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74251,
     "status": "ok",
     "timestamp": 1577434968729,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "6psPPzENQk7m",
    "outputId": "910ce017-2701-4842-b7dc-4949ab7a61a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>answers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6684668</td>\n",
       "      <td>SVN: Create a branch from branch and merge to ...</td>\n",
       "      <td>&lt;p&gt;We have a branch B1, and it is still not st...</td>\n",
       "      <td>svn|svn-merge</td>\n",
       "      <td>&lt;p&gt;Since you stated that you created B2 just t...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6927011</td>\n",
       "      <td>Is the device token as unique as the device ID?</td>\n",
       "      <td>&lt;p&gt;If we reset an iPhone, the device ID remain...</td>\n",
       "      <td>iphone|ios|devicetoken</td>\n",
       "      <td>&lt;p&gt;I assume you are referring to the device to...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6549414</td>\n",
       "      <td>How to run make in vim and open results in a s...</td>\n",
       "      <td>&lt;p&gt;I use vim for coding. When I have to compil...</td>\n",
       "      <td>vim|ide</td>\n",
       "      <td>&lt;p&gt;If you want compile and run if compile succ...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2060741</td>\n",
       "      <td>Does Objective-C use short-circuit evaluation?</td>\n",
       "      <td>&lt;p&gt;I tried something along the lines of:&lt;/p&gt;\\n...</td>\n",
       "      <td>objective-c|short-circuiting</td>\n",
       "      <td>&lt;p&gt;Objective-C is a strict superset of C.&lt;/p&gt;\\...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13392623</td>\n",
       "      <td>Returning JSONP from Jersey</td>\n",
       "      <td>&lt;p&gt;I am currently using Jersey to return JSON....</td>\n",
       "      <td>jersey|jsonp</td>\n",
       "      <td>&lt;p&gt;Take a look at the &lt;a href=\"http://java.net...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  ... score\n",
       "0   6684668  ...    10\n",
       "1   6927011  ...    22\n",
       "2   6549414  ...    -2\n",
       "3   2060741  ...    10\n",
       "4  13392623  ...     9\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 65659,
     "status": "ok",
     "timestamp": 1577434968732,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "nM1pQS6nOHe3",
    "outputId": "e7f459f1-ed5f-43ba-8e5c-d7ff078d034e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4ECRypCRVAY"
   },
   "source": [
    "## Data analysis and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kd3pv52WSFz7"
   },
   "source": [
    "### Loding the language for the text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aDXDky-8RY1r"
   },
   "outputs": [],
   "source": [
    "EN = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HjIkF2KR1PU"
   },
   "source": [
    "### Missing value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1264,
     "status": "ok",
     "timestamp": 1577265063326,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "WRv5iZQNRvtX",
    "outputId": "3e0e35c9-c72e-4395-ce4b-582ad2c01bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "title      0\n",
       "body       0\n",
       "tags       0\n",
       "answers    0\n",
       "score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wdHkrKESRkN"
   },
   "source": [
    "#### Observation\n",
    "- Is good to see that there is no missing value in the dataset.\n",
    "- Hence no need for the data imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ypb2EHkRXnzH"
   },
   "source": [
    "### Checking for Duplicate in data if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8635,
     "status": "ok",
     "timestamp": 1577265870248,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "AbP4TanvXwZh",
    "outputId": "96c7435d-6368-4fb1-a9a4-fae5695386b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEt97tzxX3-E"
   },
   "source": [
    "#### Observation\n",
    "- As you can see there are some duplicates in the data\n",
    "- so in the next cell I will combine it and try to create a corpus based on their common questions and tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amay4kHaS0Pq"
   },
   "source": [
    "### Creating a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As there are many repeated qustions but with the unique answer so I combine the answer and score of them in the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76679,
     "status": "ok",
     "timestamp": 1577434989896,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "60fQPk-4R9Du",
    "outputId": "6e2ef63a-6798-45c7-87cb-5c4398a8489e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\n",
      "in a future version.\n",
      "\n",
      "For column-specific groupby renaming, use named aggregation\n",
      "\n",
      "    >>> df.groupby(...).agg(name=('column', aggfunc))\n",
      "\n",
      "  return super().aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "combination = {\n",
    "    # Function 1\n",
    "    'answers':{\n",
    "        'combined_answers': lambda x: \"\\n\".join(x)\n",
    "    },\n",
    "    # Function 2\n",
    "    'score':{\n",
    "        'combined_score': 'sum'\n",
    "    }\n",
    "}\n",
    "# https://www.geeksforgeeks.org/python-pandas-series-agg/\n",
    "grouped_data = original_data.groupby(['id','title', 'body','tags'],as_index=False).agg(combination)\n",
    "deduped_data = pd.DataFrame(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1813,
     "status": "ok",
     "timestamp": 1577434991758,
     "user": {
      "displayName": "VASHIST NARAYAN Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ2sTI_OKjpjwoUhA-jXR-tgjiP1NZcaXcone2ZQ=s64",
      "userId": "16503262349421652367"
     },
     "user_tz": -330
    },
    "id": "Zt5yEjXxU42e",
    "outputId": "4cfb736c-6078-4fb5-f681-cbdf79473cde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>answers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>combined_answers</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>python|windows|image|pdf</td>\n",
       "      <td>&lt;p&gt;You can use ImageMagick's convert utility f...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1417</td>\n",
       "      <td>How can I get the authenticated user name unde...</td>\n",
       "      <td>&lt;p&gt;First, let's get the security consideration...</td>\n",
       "      <td>php|apache|authentication|http-authentication</td>\n",
       "      <td>&lt;p&gt;I think that you are after this&lt;/p&gt;\\n\\n&lt;pre...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3144</td>\n",
       "      <td>'Best' Diff Algorithm</td>\n",
       "      <td>&lt;p&gt;I need to implement a Diff algorithm in VB....</td>\n",
       "      <td>vb.net|diff</td>\n",
       "      <td>&lt;p&gt;I like &lt;a href=\"http://www.xmailserver.org/...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3196</td>\n",
       "      <td>SQL query, count and group by</td>\n",
       "      <td>&lt;p&gt;If I have data like this:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code...</td>\n",
       "      <td>sql</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;select name from table group by nam...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3831</td>\n",
       "      <td>How do I best detect an ASP.NET expired session?</td>\n",
       "      <td>&lt;p&gt;I need to detect when a session has expired...</td>\n",
       "      <td>asp.net|http|session</td>\n",
       "      <td>&lt;p&gt;Try the following&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;If Sess...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ...          score\n",
       "         ... combined_score\n",
       "0   502  ...             47\n",
       "1  1417  ...             37\n",
       "2  3144  ...             17\n",
       "3  3196  ...             45\n",
       "4  3831  ...              9\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UupTPoCAZGxu"
   },
   "source": [
    "## Text processing of the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lA-8SRg2b86r"
   },
   "source": [
    "Here I am creating some function which will help me out to preprocess the text data the function include the following:\n",
    "- Tokenization of the text\n",
    "- Converting the tokens to lowercase\n",
    "- Removing the punctuation from the tokens list\n",
    "- Removing the stopwords from the tokens list\n",
    "- Tokenizatio of the code string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twbw15M4VAEt"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    \"Apply tokenization using spacy to docstrings.\"\n",
    "    tokens = EN.tokenizer(text)\n",
    "    return [token.text.lower() for token in tokens if not token.is_space]\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def tokenize_code(text):\n",
    "    \"A very basic procedure for tokenizing code strings.\"\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return ' '.join(normalize(tokenize_text(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvDWwJYkafm1"
   },
   "source": [
    "**The raw text for Questions and Answers is given along with the HTML markup with which it was displayed on StackOverflow originally**. \n",
    "These refer usually to *p tags, h1-h6 tags and the code tags*\n",
    "\n",
    "- I constructed a new feature column called 'post_corpus' by combining the title, question body, and all the answers\n",
    "- I prepended the title to the question body \n",
    "- I skipped the 'code' sections because they do not offer useful information for our task\n",
    "- I constructed urls for each question by appending 'https://stackoverflow.com/questions/' with the question id\n",
    "- I constructed 2 features for sentiment using the open Source **Textblob library** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GYGUy8X7aOj4",
    "outputId": "7dab4786-5745-4598-e023-262b79e124b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155322it [37:48, 30.69s/it]"
     ]
    }
   ],
   "source": [
    "title_list = [] \n",
    "content_list = []\n",
    "url_list = []\n",
    "comment_list = []\n",
    "sentiment_polarity_list = []\n",
    "sentiment_subjectivity_list = []\n",
    "vote_list =[]\n",
    "tag_list = []\n",
    "corpus_list = []\n",
    "\n",
    "for i, row in tqdm(deduped_data.iterrows()):\n",
    "    title_list.append(row.title.values[0])    # Get question title\n",
    "    tag_list.append(row.tags.values[0])     # Get question tags\n",
    "    \n",
    "    # Questions\n",
    "    content = row.body.values[0]\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    if soup.code: soup.code.decompose()     # Remove the code section\n",
    "    tag_p = soup.p\n",
    "    tag_pre = soup.pre\n",
    "    text = ''\n",
    "    if tag_p: text = text + tag_p.get_text()\n",
    "    if tag_pre: text = text + tag_pre.get_text()\n",
    "        \n",
    "    content_list.append(str(row.title.values[0]) + ' ' + str(text))   # Append title and question body data to the updated question body\n",
    "    \n",
    "    url_list.append('https://stackoverflow.com/questions/' + str(row.id.values[0]))\n",
    "    \n",
    "    # Answers\n",
    "    content = row.answers.values[0]\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    if soup.code: soup.code.decompose()\n",
    "    tag_p = soup.p\n",
    "    tag_pre = soup.pre\n",
    "    text = ''\n",
    "    if tag_p: text = text + tag_p.get_text()\n",
    "    if tag_pre: text = text + tag_pre.get_text()\n",
    "    comment_list.append(text)\n",
    "    \n",
    "    vote_list.append(row.score.values[0])       # Append votes\n",
    "    \n",
    "    corpus_list.append(content_list[-1] + ' ' + comment_list[-1])     # Combine the updated body and answers to make the corpus\n",
    "    \n",
    "    sentiment = TextBlob(row.answers.values[0]).sentiment\n",
    "    sentiment_polarity_list.append(sentiment.polarity)\n",
    "    sentiment_subjectivity_list.append(sentiment.subjectivity)\n",
    "\n",
    "content_token_df = pd.DataFrame({'original_title': title_list, 'post_corpus': corpus_list, \n",
    "                                 'question_content': content_list, 'question_url': url_list, \n",
    "                                 'tags': tag_list, 'overall_scores':vote_list,\n",
    "                                 'answers_content': comment_list, \n",
    "                                 'sentiment_polarity': sentiment_polarity_list, \n",
    "                                 'sentiment_subjectivity':sentiment_subjectivity_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now I have taken the count of every tags and make a dictionary of it ad later on i have selected the top 100 tags  you can cange that number also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgieBAv7a1-4"
   },
   "outputs": [],
   "source": [
    "content_token_df.tags = content_token_df.tags.apply(lambda x: x.split('|'))   # Convert raw text data of tags into lists\n",
    "\n",
    "# Make a dictionary to count the frequencies for all tags\n",
    "tag_freq_dict = {}\n",
    "for tags in content_token_df.tags:\n",
    "    for tag in tags:\n",
    "        if tag not in tag_freq_dict:\n",
    "            tag_freq_dict[tag] = 0\n",
    "        else:\n",
    "            tag_freq_dict[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIqgfPqHa52Z"
   },
   "outputs": [],
   "source": [
    "most_common_tags = heapq.nlargest(100, tag_freq_dict, key=tag_freq_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "for i,tags in enumerate(content_token_df.tags.values.tolist()):\n",
    "    if len(set(tags).intersection(set(most_common_tags)))>1:   # The minimum length for common tags should be 2 because 'python' is a common tag for all\n",
    "        final_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = content_token_df.iloc[final_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After selecting the data with the top 100 tags I have done the processing of it and also normalize the numerical data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "EN = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Preprocess text for 'question_body', 'post_corpus' and a new column 'processed_title'\n",
    "final_data.question_content = final_data.question_content.apply(lambda x: preprocess_text(x))\n",
    "final_data.post_corpus = final_data.post_corpus.apply(lambda x: preprocess_text(x))\n",
    "final_data['processed_title'] = final_data.original_title.apply(lambda x: preprocess_text(x))\n",
    "\n",
    "# Normalize numeric data for the scores\n",
    "final_data['overall_scores'] = (final_data.overall_scores - final_data.overall_scores.mean()) / (final_data.overall_scores.max() - final_data.overall_scores.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.tags = final_data.tags.apply(lambda x: '|'.join(x))    # Combine the lists back into text data\n",
    "final_data.drop(['answers_content'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "final_data.to_pickle('data/Preprocessed_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stackoverflow_data_collection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
